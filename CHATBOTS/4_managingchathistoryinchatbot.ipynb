{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa26e5e",
   "metadata": {},
   "source": [
    "# Managing the Conversation History\n",
    "If converation history is left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. So it's important to add a step that limit the size of the messages you are passing in.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f484b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2294b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI assistant. Answer all question to the best of your abilities in {languages}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abe688bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "store = {}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c334ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.messages import HumanMessage\n",
    "with_message_history = RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")\n",
    "config = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "# response = with_message_history.invoke(\n",
    "#     {\"messages\":[HumanMessage(content=\"Hi my name is Aneesh\")],\"language\":\"Hindi\"},\n",
    "#     config=config\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8112675",
   "metadata": {},
   "source": [
    "'trim_messages': helps us reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be8b32b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a good AI assistant', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Cool i like chocolate.', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='the answer is 4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Thanks!', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='No problem', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Having fun', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes daddy. Ah yeah ðŸ¥µ', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages,AIMessage,HumanMessage\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=70,\n",
    "    strategy = \"last\",\n",
    "    token_counter = model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a good AI assistant\"),\n",
    "    HumanMessage(content=\"Hi! I am Aneesh\"),\n",
    "    AIMessage(content=\"Hi Aneesh!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream.\"),\n",
    "    AIMessage(content=\"Cool i like chocolate.\"),\n",
    "    HumanMessage(content=\"what is 2+2\"),\n",
    "    AIMessage(content=\"the answer is 4\"),\n",
    "    HumanMessage(content=\"Thanks!\"),\n",
    "    AIMessage(content=\"No problem\"),\n",
    "    HumanMessage(content=\"Having fun\"),\n",
    "    AIMessage(content=\"Yes daddy. Ah yeah ðŸ¥µ\")\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d5f8920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I said \"Yes daddy. Ah yeah ðŸ¥µ\" \\n\\nI apologize for that response. It was inappropriate and not aligned with my purpose as a helpful and harmless AI assistant. \\n\\nCan I try to make it up to you? Perhaps you\\'d like to ask me another question or discuss a different topic?\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(messages=itemgetter('messages')|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\":messages+[HumanMessage(content=\"What did you say after i said having fun?\")],\n",
    "        \"languages\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420cc484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
