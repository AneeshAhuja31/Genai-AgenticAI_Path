{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parts of Speech\n",
    "Parts of speech is used to give each word in a text a grammatical category: nouns, verbs, adjectives, and adverbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech = \"\"\"\"I have three visions for India. In 3000 years of our history, people from all over the world have come and invaded us, captured our lands, conquered our minds. From Alexander onwards, the Greeks, the Turks, the Mughals, the Portuguese, the British, the French, the Dutch – all of them came and looted us, took over what was ours. Yet, we have not done this to any other nation. We have not conquered anyone. We have not grabbed their land, their culture, and their history. Why? Because we respect the freedom of others. That is why my first vision is that of freedom.\n",
    "\n",
    "My second vision for India’s development. For fifty years, we have been a developing nation. It is time we see ourselves as a developed nation. We are among the top five nations in the world in terms of GDP. We have ten percent growth rate in most areas. Our poverty levels are falling. Our achievements are being globally recognized today. Yet we lack the self-confidence to see ourselves as a developed nation, as a self-reliant and self-assured nation.\n",
    "\n",
    "My third vision is that India must stand up to the world. Because I believe that unless India stands up to the world, no one will respect us. Only strength respects strength. We must be strong not only as a military power but also as an economic power. Both must go hand-in-hand.\n",
    "\n",
    "Why is the media here so negative? Why are we in India so embarrassed to recognize our own strengths, our own achievements? We are such a great nation. We have so many amazing success stories but we refuse to acknowledge them. Why?\"\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "sentences = sent_tokenize(speech)\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('``', '``'), ('I', 'PRP'), ('three', 'CD'), ('visions', 'NNS'), ('India', 'NNP'), ('.', '.')]\n",
      "[('In', 'IN'), ('3000', 'CD'), ('years', 'NNS'), ('history', 'NN'), (',', ','), ('people', 'NNS'), ('world', 'NN'), ('come', 'VBP'), ('invaded', 'VBN'), ('us', 'PRP'), (',', ','), ('captured', 'VBD'), ('lands', 'NNS'), (',', ','), ('conquered', 'VBD'), ('minds', 'NNS'), ('.', '.')]\n",
      "[('From', 'IN'), ('Alexander', 'NNP'), ('onwards', 'NNS'), (',', ','), ('Greeks', 'NNP'), (',', ','), ('Turks', 'NNP'), (',', ','), ('Mughals', 'NNP'), (',', ','), ('Portuguese', 'NNP'), (',', ','), ('British', 'NNP'), (',', ','), ('French', 'NNP'), (',', ','), ('Dutch', 'NNP'), ('–', 'NNP'), ('came', 'VBD'), ('looted', 'VBD'), ('us', 'PRP'), (',', ','), ('took', 'VBD'), ('.', '.')]\n",
      "[('Yet', 'RB'), (',', ','), ('done', 'VBN'), ('nation', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), ('conquered', 'VBD'), ('anyone', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), ('grabbed', 'VBD'), ('land', 'NN'), (',', ','), ('culture', 'NN'), (',', ','), ('history', 'NN'), ('.', '.')]\n",
      "[('Why', 'WRB'), ('?', '.')]\n",
      "[('Because', 'IN'), ('respect', 'NN'), ('freedom', 'NN'), ('others', 'NNS'), ('.', '.')]\n",
      "[('That', 'DT'), ('first', 'JJ'), ('vision', 'NN'), ('freedom', 'NN'), ('.', '.')]\n",
      "[('My', 'PRP$'), ('second', 'JJ'), ('vision', 'NN'), ('India', 'NNP'), ('’', 'NNP'), ('development', 'NN'), ('.', '.')]\n",
      "[('For', 'IN'), ('fifty', 'JJ'), ('years', 'NNS'), (',', ','), ('developing', 'VBG'), ('nation', 'NN'), ('.', '.')]\n",
      "[('It', 'PRP'), ('time', 'NN'), ('see', 'VB'), ('developed', 'JJ'), ('nation', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), ('among', 'IN'), ('top', 'JJ'), ('five', 'CD'), ('nations', 'NNS'), ('world', 'NN'), ('terms', 'NNS'), ('GDP', 'NNP'), ('.', '.')]\n",
      "[('We', 'PRP'), ('ten', 'VBP'), ('percent', 'JJ'), ('growth', 'NN'), ('rate', 'NN'), ('areas', 'NNS'), ('.', '.')]\n",
      "[('Our', 'PRP$'), ('poverty', 'NN'), ('levels', 'NNS'), ('falling', 'VBG'), ('.', '.')]\n",
      "[('Our', 'PRP$'), ('achievements', 'NNS'), ('globally', 'RB'), ('recognized', 'VBN'), ('today', 'NN'), ('.', '.')]\n",
      "[('Yet', 'RB'), ('lack', 'JJ'), ('self-confidence', 'NN'), ('see', 'NN'), ('developed', 'JJ'), ('nation', 'NN'), (',', ','), ('self-reliant', 'JJ'), ('self-assured', 'JJ'), ('nation', 'NN'), ('.', '.')]\n",
      "[('My', 'PRP$'), ('third', 'JJ'), ('vision', 'NN'), ('India', 'NNP'), ('must', 'MD'), ('stand', 'VB'), ('world', 'NN'), ('.', '.')]\n",
      "[('Because', 'IN'), ('I', 'PRP'), ('believe', 'VBP'), ('unless', 'IN'), ('India', 'NNP'), ('stands', 'VBZ'), ('world', 'NN'), (',', ','), ('one', 'CD'), ('respect', 'NN'), ('us', 'PRP'), ('.', '.')]\n",
      "[('Only', 'RB'), ('strength', 'NN'), ('respects', 'NNS'), ('strength', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), ('must', 'MD'), ('strong', 'JJ'), ('military', 'JJ'), ('power', 'NN'), ('also', 'RB'), ('economic', 'JJ'), ('power', 'NN'), ('.', '.')]\n",
      "[('Both', 'DT'), ('must', 'MD'), ('go', 'VB'), ('hand-in-hand', 'NN'), ('.', '.')]\n",
      "[('Why', 'WRB'), ('media', 'NNS'), ('negative', 'JJ'), ('?', '.')]\n",
      "[('Why', 'WRB'), ('India', 'NNP'), ('embarrassed', 'VBD'), ('recognize', 'VB'), ('strengths', 'NNS'), (',', ','), ('achievements', 'NNS'), ('?', '.')]\n",
      "[('We', 'PRP'), ('great', 'JJ'), ('nation', 'NN'), ('.', '.')]\n",
      "[('We', 'PRP'), ('many', 'JJ'), ('amazing', 'JJ'), ('success', 'NN'), ('stories', 'NNS'), ('refuse', 'VBP'), ('acknowledge', 'NN'), ('.', '.')]\n",
      "[('Why', 'WRB'), ('?', '.'), (\"''\", \"''\")]\n"
     ]
    }
   ],
   "source": [
    "for i,sentence in enumerate(sentences):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "    pos_tag = nltk.pos_tag(words)\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tokens: expected a list of strings, got a string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTaj Mahal is a beautiful monument\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39msplit():\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\OneDrive\\Desktop\\ML\\venv\\lib\\site-packages\\nltk\\tag\\__init__.py:166\u001b[0m, in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03mUse NLTK's currently recommended part of speech tagger to\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03mtag the given list of tokens.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03m:rtype: list(tuple(str, str))\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    165\u001b[0m tagger \u001b[38;5;241m=\u001b[39m _get_tagger(lang)\n\u001b[1;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_pos_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtagset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtagger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\OneDrive\\Desktop\\ML\\venv\\lib\\site-packages\\nltk\\tag\\__init__.py:120\u001b[0m, in \u001b[0;36m_pos_tag\u001b[1;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Throws Error if tokens is of string type\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tokens, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens: expected a list of strings, got a string\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    123\u001b[0m     tagged_tokens \u001b[38;5;241m=\u001b[39m tagger\u001b[38;5;241m.\u001b[39mtag(tokens)\n",
      "\u001b[1;31mTypeError\u001b[0m: tokens: expected a list of strings, got a string"
     ]
    }
   ],
   "source": [
    "\n",
    "print(nltk.pos_tag(\"Taj Mahal is a beautiful monument\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
